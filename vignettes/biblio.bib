% Encoding: UTF-8

@book{molnar,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  url       = {https://christophm.github.io/interpretable-ml-book/},
  year       = {2019},
  subtitle   = {A Guide for Making Black Box Models Explainable}
}

@misc{fisher,
    title={All Models are Wrong, but Many are Useful: Learning a Variable's Importance by Studying an Entire Class of Prediction Models Simultaneously},
    author={Aaron Fisher and Cynthia Rudin and Francesca Dominici},
    year={2018},
    eprint={1801.01489},
    archivePrefix={arXiv},
    primaryClass={stat.ME}
}

@article{goldstein,
   author = {Alex Goldstein and Adam Kapelner and Justin Bleich and Emil Pitkin},
   title = {Peeking Inside the Black Box: Visualizing Statistical Learning With Plots of Individual Conditional Expectation},
   journal = {Journal of Computational and Graphical Statistics},
   volume = {24},
   number = {1},
   pages = {44-65},
   year  = {2015},
   publisher = {Taylor & Francis},
   doi = {10.1080/10618600.2014.907095},
   URL = {https://doi.org/10.1080/10618600.2014.907095},
   eprint = {https://doi.org/10.1080/10618600.2014.907095}
}

@article{friedman2001,
   author = "Friedman, Jerome H.",
   doi = "10.1214/aos/1013203451",
   fjournal = "The Annals of Statistics",
   journal = "Ann. Statist.",
   month = "10",
   number = "5",
   pages = "1189--1232",
   publisher = "The Institute of Mathematical Statistics",
   title = "Greedy function approximation: A gradient boosting machine.",
   url = "https://doi.org/10.1214/aos/1013203451",
   volume = "29",
   year = "2001"
}

@misc{apley,
    title={Visualizing the Effects of Predictor Variables in Black Box Supervised Learning Models},
    author={Daniel W. Apley and Jingyu Zhu},
    year={2016},
    eprint={1612.08468},
    archivePrefix={arXiv},
    primaryClass={stat.ME}
}

@misc{gosiewska,
    title={Do Not Trust Additive Explanations},
    author={Alicja Gosiewska and Przemyslaw Biecek},
    year={2019},
    eprint={1903.11420},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{friedman2008,
 ISSN = {19326157},
 URL = {http://www.jstor.org/stable/30245114},
 abstract = {General regression and classification models are constructed as linear combinations of simple rules derived from the data. Each rule consists of a conjunction of a small number of simple statements concerning the values of individual input variables. These rule ensembles are shown to produce predictive accuracy comparable to the best methods. However, their principal advantage lies in interpretation. Because of its simple form, each rule is easy to understand, as is its influence on individual predictions, selected subsets of predictions, or globally over the entire space of joint input variable values. Similarly, the degree of relevance of the respective input variables can be assessed globally, locally in different regions of the input space, or at individual prediction points. Techniques are presented for automatically identifying those variables that are involved in interactions with other variables, the strength and degree of those interactions, as well as the identities of the other variables with which they interact. Graphical representations are used to visualize both main and interaction effects.},
 author = {Jerome H. Friedman and Bogdan E. Popescu},
 journal = {The Annals of Applied Statistics},
 number = {3},
 pages = {916--954},
 publisher = {Institute of Mathematical Statistics},
 title = {Predictive Learning via Rule Ensembles},
 volume = {2},
 year = {2008}
}



